{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3IbomL8dMTi",
    "outputId": "3fa8eb7c-ddf2-4f98-edee-0c49db6502e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df=df[:5000]\n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HbiMFpgRdMUJ",
    "outputId": "21c00698-7f2a-4ce4-e665-f7a2feaab6fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "    dfnlp=dfnlp[:5000]\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebook\")\n",
    "\n",
    "if os.path.isfile('df_fe_without_preprocessing_train.csv'):\n",
    "    dfppro = pd.read_csv(\"df_fe_without_preprocessing_train.csv\",encoding='latin-1')\n",
    "    dfppro=dfppro[:5000]\n",
    "else:\n",
    "    print(\"download df_fe_without_preprocessing_train.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnlp.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1, inplace=True)\n",
    "dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1, inplace=True)\n",
    "data=pd.concat([df,dfnlp,dfppro],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = data['is_duplicate']\n",
    "data.drop(['is_duplicate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr,X_test, y_tr, y_test = train_test_split(data, y_true, stratify=y_true, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# merge texts\n",
    "#questions_train = list(X_train['question1']) + list(X_train['question2'])\n",
    "#questions_test = list(X_test['question1']) + list(X_test['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_ques1_tr= tfidf.fit_transform(X_tr['question1'].values)\n",
    "tfidf_ques1_test= tfidf.transform(X_test['question1'].values)\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_ques2_tr= tfidf.fit_transform(X_tr['question2'].values)\n",
    "tfidf_ques2_test= tfidf.transform(X_test['question2'].values)\n",
    "\n",
    "#tfidf_tr=hstack((tfidf_ques1_tr,tfidf_ques2_tr))\n",
    "#tfidf_test=hstack((tfidf_ques1_test,tfidf_ques2_test))\n",
    "\n",
    "X_tr['q1_feats_m'] = list(tfidf_ques1_tr.toarray())\n",
    "X_test['q1_feats_m'] = list(tfidf_ques1_test.toarray())\n",
    "X_tr['q2_feats_m'] = list(tfidf_ques2_tr.toarray())\n",
    "X_test['q2_feats_m'] = list(tfidf_ques2_test.toarray())\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "#word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data : (3500, 35)\n",
      "Number of data points in test data : (1500, 35)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data :\",X_tr.shape)\n",
    "print(\"Number of data points in test data :\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "X_tr.drop(['id','qid1','qid2','question1','question2'],axis=1,inplace=True)\n",
    "X_test.drop(['id','qid1','qid2','question1','question2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data : (3500, 28)\n",
      "Number of data points in test data : (1500, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data :\",X_tr.shape)\n",
    "print(\"Number of data points in test data :\",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_q1_tr = pd.DataFrame(X_tr.q1_feats_m.values.tolist(), index= X_tr.index)\n",
    "X_q1_test = pd.DataFrame(X_test.q1_feats_m.values.tolist(), index= X_test.index)\n",
    "X_q2_tr = pd.DataFrame(X_tr.q2_feats_m.values.tolist(), index= X_tr.index)\n",
    "X_q2_test = pd.DataFrame(X_test.q2_feats_m.values.tolist(), index= X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in train data q1 : (3500, 6557)\n",
      "Number of data points in test data q1: (1500, 6557)\n",
      "Number of data points in train data q2: (3500, 6327)\n",
      "Number of data points in test data q2: (1500, 6327)\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of data points in train data q1 :\",X_q1_tr.shape)\n",
    "print(\"Number of data points in test data q1:\",X_q1_test.shape)\n",
    "print(\"Number of data points in train data q2:\",X_q2_tr.shape)\n",
    "print(\"Number of data points in test data q2:\",X_q2_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr.drop(['q1_feats_m','q2_feats_m'],axis=1,inplace=True)\n",
    "X_test.drop(['q1_feats_m','q2_feats_m'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr=pd.concat([X_tr,X_q1_tr,X_q2_tr],axis=1)\n",
    "X_test=pd.concat([X_test,X_q1_test,X_q2_test],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ozz83vh4dMWU",
    "outputId": "e5b30f77-2849-4b08-9949-0912ec0db418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe : 16\n",
      "Number of features in preprocessed dataframe : 12\n",
      "Number of features in question1 w2v train dataframe : 6557\n",
      "Number of features in question2 w2v train dataframe : 6327\n",
      "Number of features in question1 w2v test dataframe : 6557\n",
      "Number of features in question2 w2v test dataframe : 6327\n",
      "Number of features in final dataframe  : 25796\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe :\", dfnlp.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", dfppro.shape[1])\n",
    "print(\"Number of features in question1 w2v train dataframe :\", X_q1_tr.shape[1])\n",
    "print(\"Number of features in question2 w2v train dataframe :\", X_q2_tr.shape[1])\n",
    "print(\"Number of features in question1 w2v test dataframe :\", X_q1_test.shape[1])\n",
    "print(\"Number of features in question2 w2v test dataframe :\", X_q2_test.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", dfnlp.shape[1]+dfppro.shape[1]+X_q1_tr.shape[1]+X_q2_tr.shape[1]+X_q1_test.shape[1]+X_q2_tr.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_columns=X_tr.columns\n",
    "X_test_columns=X_test.columns\n",
    "y_tr_columns=y_tr.name\n",
    "y_test_columns=y_test.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HmfZ5Q1zdMWl"
   },
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "#https://stackoverflow.com/questions/37756991/best-way-to-join-two-large-datasets-in-pandas\n",
    "\n",
    "X_tr.to_csv('X_tr.csv',index=False,header=X_tr_columns)\n",
    "X_test.to_csv('X_test.csv',index=False,header=X_test_columns)\n",
    "y_tr.to_csv('y_tr.csv',index=False,header=y_tr_columns)\n",
    "y_test.to_csv('y_test.csv',index=False,header=y_test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def multiple_dfs(df_list, sheets, file_name, spaces):\n",
    "#    writer = pd.ExcelWriter(file_name,engine='xlsxwriter')   \n",
    "#    row = 0\n",
    "#    for dataframe in df_list:\n",
    "#        dataframe.to_excel(writer,sheet_name=sheets,startrow=0, startcol=row)   \n",
    "#        row = row + len(dataframe.columns) + spaces + 1\n",
    "#    writer.save()\n",
    "#df_list=[df1,df2]\n",
    "## run function\n",
    "#multiple_dfs(df_list, 'Validation', 'test2.xlsx', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#>>> from sqlalchemy import create_engine\n",
    "#>>> engine = create_engine('sqlite:///data.db')\n",
    "#X_tr.to_sql('X_tr', engine, if_exists='replace')\n",
    "#X_test.to_sql('X_test', engine, if_exists='replace')\n",
    "#y_tr.to_sql('y_tr', engine, if_exists='replace')\n",
    "#y_test.to_sql('y_test', engine, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
